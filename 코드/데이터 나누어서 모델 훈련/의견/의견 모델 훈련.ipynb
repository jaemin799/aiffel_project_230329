{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be671b8f",
   "metadata": {},
   "source": [
    "# 알집 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e1ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('opinion_train.zip', 'r') as zip:\n",
    "    zip.extractall('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0c59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"opinion_test.zip\", \"r\") as zip:\n",
    "    zip.extractall(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fcab5b",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef07bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/aiffel/aiffel/aiffel_project/opinion_model/train/┴╓└σ/┴╓└σ_░φ╡ε_2╟╨│Γ_ESSAY_53067.json', '/aiffel/aiffel/aiffel_project/opinion_model/train/┴╓└σ/┴╓└σ_┴▀╡ε_3╟╨│Γ_ESSAY_65078.json', '/aiffel/aiffel/aiffel_project/opinion_model/train/┴╓└σ/┴╓└σ_░φ╡ε_2╟╨│Γ_ESSAY_77120.json', '/aiffel/aiffel/aiffel_project/opinion_model/train/┴╓└σ/┴╓└σ_┴▀╡ε_3╟╨│Γ_ESSAY_52311.json', '/aiffel/aiffel/aiffel_project/opinion_model/train/┴╓└σ/┴╓└σ_░φ╡ε_1╟╨│Γ_ESSAY_62856.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "train_dir = os.getenv(\"HOME\") + \"/aiffel/aiffel_project/opinion_model/train/┴╓└σ/*\"\n",
    "train_list = glob.glob(train_dir)\n",
    "\n",
    "print(train_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "730ed665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/aiffel/aiffel/aiffel_project/opinion_model/test/┴╓└σ/┴╓└σ_░φ╡ε_2╟╨│Γ_ESSAY_85982.json', '/aiffel/aiffel/aiffel_project/opinion_model/test/┴╓└σ/┴╓└σ_░φ╡ε_2╟╨│Γ_ESSAY_86782.json', '/aiffel/aiffel/aiffel_project/opinion_model/test/┴╓└σ/┴╓└σ_░φ╡ε_2╟╨│Γ_ESSAY_86088.json', '/aiffel/aiffel/aiffel_project/opinion_model/test/┴╓└σ/┴╓└σ_░φ╡ε_2╟╨│Γ_ESSAY_85462.json', '/aiffel/aiffel/aiffel_project/opinion_model/test/┴╓└σ/┴╓└σ_┴▀╡ε_2╟╨│Γ_ESSAY_72388.json']\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.getenv(\"HOME\") + \"/aiffel/aiffel_project/opinion_model/test/┴╓└σ/*\"\n",
    "test_list = glob.glob(test_dir)\n",
    "\n",
    "print(test_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7950d479",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42eb269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 코로나 백신에 대한 지적재산권의 권리를 보장해주어야 한다고 생각합니다. 왜냐하면 백신을 개발하기 위해서 수많은 사람들과 천문학적인 비용이 들었을텐데 손익분기점도 넘기기 전에 돈을 포기하고 얼굴도 모르는 전 세계 사람들을 위해 자신의 시간과 노력을 기부하면 명예를 준다고 하면 그 누가 코로나 백신을 개발하려고 할까라는 의문을 가지게 합니다. 원래 돈을 버는 사람들은 혼란 속에서 돈을 번다고 합니다. 주식시장도 마찬가지라고 생각합니다. 얼마 전 삼성전자의 주가가 9만원일 때가 있었습니다. 그런데 코로나 백신이 개발되고 점점 위드 코로나를 하는 나라가 많아짐에 따라 전자기기의 수요가 줄 것으로 예상되 삼성전자의 주요 생산품인 반도체의 재고량이 많아져 주가가 9만원을 찍고 급락했습니다. 하지만 그것도 잠시 6만 9천원까지 떨어진 삼성저자의 주가는 점점 안정세를 보이며 7만원 대 박스권 소위말해 안정권에 들어섰다는 것입니다. 삼성전자 주가가 안정권에 들어선 이유는 바로 페닉바잉이라는 현상으로 설명할 수 있습니다. 페닉바잉이랑 자신이 소유한 주식이 가격이 떨어져 급락하는 것을 막기 위해 더 구입한다는 것입니다. 그래서 삼성전자의 주가가 떨어지다가 다시 안정권을 가졌다고 생각합니다. 세상도 마찬가지라고 생각합니다. 혼란한 상황 속에 그 혼란을 정리하는 사람이 돈을 버는 것이 마땅하다고 생각합니다. 코로나라는 혼란한 상황 속에 백신 개발이라는 혼란을 잠재우는 사람이 바로 돈을 버는 것입니다. 혹자는 돈 없는 후진국은 그럼 어떻게 백신을 구매하라는 것이냐라고 합니다. 근데 저는 그 생각이 너무 오지랖이라고 생각합니다. 우리나라에서 백신을 못맞고있는 사람부터 먼저 걱정을 해야지 생판 모르는 남의나라 다른 인종을 걱정하는 것이 정말 오지랖이라고 생각합니다. 그래서 저는 코로나 백신에 대한 지적재산권을 보장해주어야 한다고 생각합니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for file in train_list:\n",
    "    with open(file, 'r') as f:\n",
    "        json_file = json.load(f)\n",
    "        only_txt = json_file[\"essay_txt\"]\n",
    "        only_txt = only_txt.replace(\"#@문장구분#\", \"\")\n",
    "        only_txt = only_txt.replace(\"\\b\", \"\")\n",
    "        only_txt = only_txt.replace(\"\\n\", \"\")\n",
    "        corpus.append(only_txt)\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918045de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ' '.join(map(str, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87baad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저는 코로나 백신에 대한 지적재산권의 권리를 보장해주어야 한다고 생각합니다. 왜냐하면 백신을 개발하기 위해서 수많은 사람들과 천문학적인 비용이 들었을텐데 손익분기점도 넘기기 전에 '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f6b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전세계적인 백신 생산체계를 갖추는 것은 코로나19가 종식된 이후에도 중요하다. 이미 지구촌은 코로나19 전에 메르스, 싸스라는 전염병의 대유행을 겪었다. 바이러스 창궐은 주기적 양상을 보이고 있고 외국여행을 이웃집에 가듯이 하는 유사일에 없었던 발전된 현대인의 삶의 방식은 전염병의 확산을 가속화 시킨다. 앞으로도 전세계는 계속되는 전염병과 싸워야 한다. 사람이 죽어 나가는데 모든 가능성을 찾아보는 것은 고사하고 백신 지식재산권(지적재산권, 특허권) 반대만 외치는 것은 황당하기 그지없지만 바이러스로 부터 살아남을 수 있는 미래의 조건은 전세계적인 백신의 생산체계를 갖추었느냐 아니냐에 달린 문제인데도 이를 부정하는 것은 어떤 합리적 주장을 내세워도 인정될수 없다. 사람의 생명이 가장 우선한다는 인류의 합의된 전제는 어디갔는가? 백신 지식재산권 면제는 현재의 생명뿐만 아니라 미래의 생명을 살리는 길이기도 하다. 그러기 위해서는 백신이 특정 국가나 회사의 독점물로 가 아니라 일류의 공영재가 되지 않으면 안된다. 답은 명백하다. 전염병이 창궐하는 상황에 '나'만 '우리'만 살겠다는 생존 논리는 성공할 수 없다. 오직 모두가 함께 산다는 방법을 통해서만 나와 우리의 생존도 보장받을 수 있다. 이기심을 내려놓고 돈의 논리, 시장의 논리 밖에서 생각할 때 인간의 생명이 가장 우선한다는 인도주의가 보일 것이다. 그래서 어서 빨리 백신에 대한 지적재산권이 완화되어 전 세계적으로 유행하는 코로나가 빨리 종식되었으면 좋겠습니다.\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for file in test_list:\n",
    "    with open(file, 'r') as f:\n",
    "        json_file = json.load(f)\n",
    "        only_txt = json_file[\"essay_txt\"]\n",
    "        only_txt = only_txt.replace(\"#@문장구분#\", \"\")\n",
    "        only_txt = only_txt.replace(\"\\b\", \"\")\n",
    "        only_txt = only_txt.replace(\"\\n\", \"\")\n",
    "        corpus.append(only_txt)\n",
    "        \n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e649937",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ' '.join(map(str, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c15f31f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'전세계적인 백신 생산체계를 갖추는 것은 코로나19가 종식된 이후에도 중요하다. 이미 지구촌은 코로나19 전에 메르스, 싸스라는 전염병의 대유행을 겪었다. 바이러스 창궐은 주기적 양'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd3267",
   "metadata": {},
   "source": [
    "# 프리트레인 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8570570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:660: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "                                                   bos_token = \"</s>\",\n",
    "                                                   eos_token = \"</s>\",\n",
    "                                                   pad_token = \"<pad>\",\n",
    "                                                   unk_token = \"<unk>\",\n",
    "                                                   mask_token = \"<mask>\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f9975",
   "metadata": {},
   "source": [
    "# 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13098346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in /opt/conda/lib/python3.9/site-packages (2.7.11)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (from fastai) (21.3.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: spacy<4 in /opt/conda/lib/python3.9/site-packages (from fastai) (3.5.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from fastai) (2.26.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from fastai) (6.0)\n",
      "Requirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.9/site-packages (from fastai) (8.3.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from fastai) (1.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.9/site-packages (from fastai) (0.10.1+cu111)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from fastai) (1.3.3)\n",
      "Requirement already satisfied: torch<1.14,>=1.7 in /opt/conda/lib/python3.9/site-packages (from fastai) (1.9.1+cu111)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /opt/conda/lib/python3.9/site-packages (from fastai) (1.5.28)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from fastai) (3.4.3)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.9/site-packages (from fastai) (0.0.7)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.9/site-packages (from fastai) (1.0.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from fastai) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (1.21.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (1.10.7)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (59.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (3.0.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (4.62.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (2.4.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (8.1.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (0.7.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<4->fastai) (2.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->fastai) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch<1.14,>=1.7->fastai) (4.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->fastai) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->fastai) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->fastai) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->fastai) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<4->fastai) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<4->fastai) (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f944aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fastai\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23d577d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def encodes(self, x):\n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "    \n",
    "    def decodes(self,x):\n",
    "        return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a63d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splits = [[0], [1]]\n",
    "\n",
    "tls = TfmdLists([train_data, test_data], TransformersTokenizer(tokenizer), splits=splits,\n",
    "               dl_type=LMDataLoader)\n",
    "\n",
    "batch, seq_len = 8, 256\n",
    "\n",
    "dls = tls.dataloaders(bs=batch, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18383f2d",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self):\n",
    "        self.learn.pred = self.pred[0]\n",
    "        \n",
    "learn = Learner(dls, model, loss_fun=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()\n",
    "lr = learn.lr_find()\n",
    "print(lr)\n",
    "learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876e45f",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27bab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"전세계적인 백신 생산체계를 갖추는 것은 코로나19가 종식된 이후에도 중요하다.\"\n",
    "prompt_ids = tokenizer.decode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp,\n",
    "                            max_length=128,\n",
    "                            bos_token_id=tokenizer.bos_token_id,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            unk_token_id=tokenizer.unk_token_id,\n",
    "                            mask_token_id=tokenizer.mask_token_id,\n",
    "                            repetition_penalty=2.0,\n",
    "                            use_cache=True)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea97c6",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"opinion_trained.pkl\", \"wb\") as f:\n",
    "    pickle.dump(learn, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
